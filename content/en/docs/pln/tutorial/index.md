---
title: "En la pr치ctica con Hugging Face"
description: "Manos a la obra con Hugging Face"
lead: "Manos a la obra con 游뱅Hugging Face游뱅! una herramienta de 'transformadores' muy poderosa que nos ayuda a convertir texto (letras-palabras) a datos num칠ricos y poder analizarlos de diferentes formas."
date: 2020-10-06T08:49:31+00:00
lastmod: 2020-10-06T08:49:31+00:00
draft: false
images: []
menu:
  docs:
    parent: "reportes"
weight: 630
toc: true
---

## Resumen

El prop칩sito es analizar los sentimientos de comentarios escritos por usuarios en una plataforma popular de viajes sobre su experiencia en playas tur칤sticas. 

El proceso consta b치sicamente de 3 pasos:

- Extracci칩n de comentarios en la plataforma de viajes escogida. A este proceso se le denomina "web scraping".

- Organizar los comentarios en una base de datos de f치cil manipulaci칩n.

- Tokenizaci칩n de texto con Hugging Face游뱅. Se usa un Modelo BERT multiling칲e por lo que es posible trabajar con otros idiomas diferentes al espa침ol. El modelo ha sido entrenado en ingl칠s, alem치n, holand칠s o franc칠s, entre otros.


## Pre-requisitos

Para una mejor comprensi칩n del An치lisis de Sentimientos con Hugging Face y BERT, ayudar칤a tener nociones b치sicas de **Python** y de c칩mo trabajar en un Jupyter Notebook.

Este [游녤art칤culo](https://grammaloreto.netlify.app/analisis-sent/) ilustra lo que vamos a hacer.

```bash
python --version # tienes python instalado?
```

## 1. Web Scraping de comentarios
Para extraer los comentarios de las playas en la plataforma de viajes escogida, se va a usar una librer칤a de **python** llamada *Beatiful Soup*. 

Como se mencion칩 en los pre-requisitos se trabajar치 en un **Jupyter notebook**, el cual es un entorno inform치tico que soporta python para correr c칩digo por m칩dulos. 

Estas son las librer칤as para el "web scraping":

```bash
from bs4 import BeautifulSoup
import requests
import re
```

**Request** es una librer칤a que permite hacer solicitudes HTTP para interactuar y "consumir" datos de la web. En el par칠ntesis va una URL o direcci칩n del sitio web donde est치n los comentarios.

```bash
data = requests.get("https://www.tripadvisor.co/Attraction_Review-g297482-d1024602-Reviews-Johnny_Cay-San_Andres_Island_San_Andres_and_Providencia_Department.html")
```

A continuaci칩n entra en acci칩n **beautiful soup**, al tomar el c칩digo *html* de la web escogida y atrapando s칩lo las etiquetas que se le indican. 

```bash
soup = BeautifulSoup(data.text, 'html.parser')
for div in soup.find_all("div"):
    regex = re.compile('.*pIRBV.*')
    results = soup.find_all('div',{'class':regex})
    reviews = [result.text for result in results]
```

Despu칠s de estas pocas l칤neas de c칩digo son extra칤dos todos los comentarios de la url solicitada. Para confirmar, llame los reviews y aparecer치n.

```bash
reviews
```

## 2. Base de Datos (df)

Teniendo todos los comentarios en la variable *reviews* lo siguiente ser치 agrupar/ordenar los comentarios en una Base de Datos (data frame).

Para este paso se usan 2 de las librer칤as mas populares de **python:** **pandas** y **numpy**.

```bash
import pandas as pd
import numpy as np
```

Con una simple l칤nea de c칩digo quedar치n todos los *reviews* en un df (data frame o base de datos).

```bash
df = pd.DataFrame(np.array(reviews), columns=['review'])
```

## 3. Tokenizaci칩n de Palabras

Tokenizar o asignarle un valor num칠rico a cada palabra que conforma un comentario, es de los motivos principales por el que utilizamos Hugging Face y los transformadores.

Para poder usar esta biblioteca es necesario instalarla primero en el notebook o en el ambiente con el que se est치 trabajando.

```bash
!pip install transformers 
```

Una vez instalado Hugging Face (transformadores) se pueden llamar los m칩dulos de "tokenizaci칩n".

>De igual forma se usa PyTorch, para una mejor experiencia con los transformadores.

```bash
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
```
### Modelo Clasificaci칩n de Texto

Hay modelos en muchos idiomas, entrenados con distintos tipos de datos. [Modelos de Clasificaci칩n de Texto en Hugging Face.](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads)

El Modelo escogido es un BERT multiling칲e (nlptown) entrenado con comentarios calificados de 1-5. Por este motivo nuestro an치lisis de sentimientos de playas tendr치 una calificaci칩n igual, de 1-5, donde 1-2 son malas experiencias, 3 neutral y 4-5 buenas experiencias.

De esta forma se incorpora el modelo BERT de nlptown a nuestro an치lisis:

```bash
tokenizer = AutoTokenizer.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")

model = AutoModelForSequenceClassification.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
```

Ahora s칤 es momento de tokenizar los *reviews*:

```bash
result = model(tokens)
def sentiment_score(review):
    tokens = tokenizer.encode(review, return_tensors='pt')
    result = model(tokens)
    return int(torch.argmax(result.logits))+1
```

Al correr la funci칩n anterior se podr치 usar sobre nuestra base de datos! 

Lo siguiente ser치 adicionar una columna nueva a la df llamada **sentiment** que es donde ir치 la calificaci칩n (1-5) de cada playa. Esta columna aplica el c칩digo anterior (sentiment-score) en base a una funci칩n lambda especificada.

```bash
df['sentiment'] = df['review'].apply(lambda x: sentiment_score(x[:512]))
```

El resultado final es una base de datos (df) con 2 columnas: la primera con los reviews o comentarios extra칤dos y la segunda llamada 'sentiment' con la calificaci칩n de 1 a 5 o "sentimiento" de los usuarios sobre las playas.

Para una mejor comprensi칩n de los resultados obtenidos en la columna 'sentiment', se puede realizar estad칤stica descriptiva b치sica (histogramas, medias, promedios etc) con *pandas* o *numpy* y as칤 tener un mejor panorama de las opiniones asociadas a las playas.

Si desea profundizar con algunos an치lisis de sentimientos hechos previamente a playas Latinoamericas, puede revisar este [repositorio de GitHub.](https://github.com/grammaloreto/BeachSentimentAnalysis)






































